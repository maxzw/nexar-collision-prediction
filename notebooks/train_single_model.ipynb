{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import wandb\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nexar.data import NexarDataModule, NexarDataset, pad_to_square\n",
    "from nexar.model import NexarClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 980000\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaxzw\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb/run-20250513_190036-gn6e7ygb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/maxzw/nexar-collision-prediction-private/runs/gn6e7ygb' target=\"_blank\">resilient-flower-16</a></strong> to <a href='https://wandb.ai/maxzw/nexar-collision-prediction-private' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/maxzw/nexar-collision-prediction-private' target=\"_blank\">https://wandb.ai/maxzw/nexar-collision-prediction-private</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/maxzw/nexar-collision-prediction-private/runs/gn6e7ygb' target=\"_blank\">https://wandb.ai/maxzw/nexar-collision-prediction-private/runs/gn6e7ygb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name               | Type              | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | image_backbone     | ResNet            | 11.2 M | train\n",
      "1 | mask_flow_backbone | ResNet            | 11.2 M | train\n",
      "2 | classifier         | Sequential        | 1.0 K  | train\n",
      "3 | loss_fn            | BCEWithLogitsLoss | 0      | train\n",
      "4 | train_accuracy     | BinaryAccuracy    | 0      | train\n",
      "5 | val_accuracy       | BinaryAccuracy    | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "22.4 M    Total params\n",
      "89.416    Total estimated model params size (MB)\n",
      "141       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nexar/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nexar/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/opt/miniconda3/envs/nexar/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (43) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 43/43 [01:48<00:00,  0.40it/s, v_num=7ygb, train_loss_step=0.575, train_acc_step=0.833, val_loss=0.506, val_acc=0.767, train_loss_epoch=0.639, train_acc_epoch=0.641]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 43/43 [01:34<00:00,  0.46it/s, v_num=7ygb, train_loss_step=0.276, train_acc_step=1.000, val_loss=0.539, val_acc=0.773, train_loss_epoch=0.563, train_acc_epoch=0.724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.007 >= min_delta = 0.0. New best score: 0.773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 43/43 [01:30<00:00,  0.48it/s, v_num=7ygb, train_loss_step=0.515, train_acc_step=0.667, val_loss=0.473, val_acc=0.780, train_loss_epoch=0.575, train_acc_epoch=0.704]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.007 >= min_delta = 0.0. New best score: 0.780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 43/43 [01:35<00:00,  0.45it/s, v_num=7ygb, train_loss_step=0.519, train_acc_step=0.667, val_loss=0.608, val_acc=0.733, train_loss_epoch=0.540, train_acc_epoch=0.738]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_acc did not improve in the last 5 records. Best score: 0.780. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 43/43 [01:35<00:00,  0.45it/s, v_num=7ygb, train_loss_step=0.519, train_acc_step=0.667, val_loss=0.608, val_acc=0.733, train_loss_epoch=0.540, train_acc_epoch=0.738]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇███</td></tr><tr><td>train_acc_epoch</td><td>▁▄▅▆▅██▇▆▇</td></tr><tr><td>train_acc_step</td><td>▁▅▆▃▅▆▅█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▂▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▄▂▅▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>val_acc</td><td>▇▆▁██▂▂▆▇▅</td></tr><tr><td>val_loss</td><td>▂▄▇▃▁█▆▂▁▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_acc_epoch</td><td>0.73778</td></tr><tr><td>train_acc_step</td><td>0.78125</td></tr><tr><td>train_loss_epoch</td><td>0.54001</td></tr><tr><td>train_loss_step</td><td>0.47471</td></tr><tr><td>trainer/global_step</td><td>429</td></tr><tr><td>val_acc</td><td>0.73333</td></tr><tr><td>val_loss</td><td>0.6079</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resilient-flower-16</strong> at: <a href='https://wandb.ai/maxzw/nexar-collision-prediction-private/runs/gn6e7ygb' target=\"_blank\">https://wandb.ai/maxzw/nexar-collision-prediction-private/runs/gn6e7ygb</a><br> View project at: <a href='https://wandb.ai/maxzw/nexar-collision-prediction-private' target=\"_blank\">https://wandb.ai/maxzw/nexar-collision-prediction-private</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb/run-20250513_190036-gn6e7ygb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "random_seed = np.random.randint(0, 1e6)\n",
    "seed_everything(random_seed, workers=True)\n",
    "\n",
    "# Initialize trainin data module\n",
    "train_df = pd.read_parquet(\"../data/processed/train.parquet\")\n",
    "datamodule = NexarDataModule(\n",
    "    train_df=train_df,\n",
    "    batch_size=32,\n",
    "    val_size=0.1,\n",
    "    transform=T.Compose([\n",
    "        T.Lambda(pad_to_square),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomAffine(degrees=5, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=5),\n",
    "    ]),\n",
    "    test_transform=T.Compose([\n",
    "        T.Lambda(pad_to_square),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = NexarClassifier(\n",
    "    lr=1e-3,\n",
    "    hidden_layers=[],\n",
    "    dropout=None,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    logger=WandbLogger(project=\"nexar-collision-prediction-private\", save_dir=\"../logs\"),\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor=\"val_acc\", mode=\"max\", save_top_k=1),\n",
    "        EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5),\n",
    "    ],\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "# Log seed\n",
    "trainer.logger.experiment.config.update({\"seed\": random_seed})\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, datamodule=datamodule)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model path: ../logs/nexar-collision-prediction-private/gn6e7ygb/checkpoints/epoch=04-val_acc=0.78.ckpt\n",
      "Best model id: gn6e7ygb\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = NexarClassifier.load_from_checkpoint(best_model_path)\n",
    "best_model.eval()\n",
    "best_model_id = best_model_path.split(\"/\")[3]\n",
    "\n",
    "print(f\"Best model path: {best_model_path}\")\n",
    "print(f\"Best model id: {best_model_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [03:36<00:00, 10.33s/it]\n",
      "100%|██████████| 21/21 [03:44<00:00, 10.70s/it]\n",
      "100%|██████████| 21/21 [03:43<00:00, 10.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00204</td>\n",
       "      <td>0.078478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00030</td>\n",
       "      <td>0.426809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00146</td>\n",
       "      <td>0.323937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00020</td>\n",
       "      <td>0.183800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00511</td>\n",
       "      <td>0.786208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target\n",
       "0  00204  0.078478\n",
       "1  00030  0.426809\n",
       "2  00146  0.323937\n",
       "3  00020  0.183800\n",
       "4  00511  0.786208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_parquet(\"../data/processed/test.parquet\")\n",
    "\n",
    "predictions = {}\n",
    "indices = [0, 1, 2]\n",
    "weights = [0.2, 0.3, 0.5]\n",
    "\n",
    "# Get predictions for each frame\n",
    "for frame_idx in indices:\n",
    "    test_dataset = NexarDataset(\n",
    "        test_df, \n",
    "        frame_idx=frame_idx, \n",
    "        return_label=False, \n",
    "        transform=datamodule.test_transform,\n",
    "    )\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=False)\n",
    "    \n",
    "    preds = []\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch)\n",
    "        pred = torch.sigmoid(pred).squeeze().detach().tolist()\n",
    "        preds.extend(pred)\n",
    "    \n",
    "    predictions[frame_idx] = preds\n",
    "\n",
    "# Take weighted average of predictions\n",
    "final_predictions = np.zeros(len(test_df))\n",
    "for i, frame_idx in enumerate(indices):\n",
    "    final_predictions += np.array(predictions[frame_idx]) * weights[i]\n",
    "final_predictions = final_predictions / sum(weights)\n",
    "\n",
    "# Save predictions\n",
    "submission_df = pd.DataFrame({\"id\": test_df[\"id\"].apply(lambda x: str(x).zfill(5)), \"target\": final_predictions})\n",
    "submission_df.to_csv(f\"../data/processed/submission_{best_model_id}.csv\", index=False)\n",
    "submission_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
